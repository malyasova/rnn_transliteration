{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I train an LSTM network\n",
    "\n",
    "on the [nettalk corpus](https://archive.ics.uci.edu/ml/datasets/Connectionist+Bench+%28Nettalk+Corpus%29)\n",
    "\n",
    "to perform English to Russian transliteration.\n",
    "\n",
    "Accuracy achieved: 93%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Masking\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import TimeDistributed\n",
    "from tensorflow.keras.layers import Bidirectional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-12-03 15:05:23--  https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/nettalk/nettalk.data\n",
      "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
      "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 541269 (529K) [application/x-httpd-php]\n",
      "Saving to: ‘nettalk.data’\n",
      "\n",
      "nettalk.data        100%[===================>] 528,58K   548KB/s    in 1,0s    \n",
      "\n",
      "2020-12-03 15:05:27 (548 KB/s) - ‘nettalk.data’ saved [541269/541269]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/nettalk/nettalk.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Letter alphabet ['b', 'j', 'i', 'z', 't', 'u', 'l', 'g', 'k', 's', 'h', 'd', 'f', 'm', 'v', 'p', 'x', 'o', 'w', 'e', 'c', 'n', 'y', 'a', 'q', 'r']\n",
      "Phoneme alphabet ['R' 'b' 'i' 'U' 'T' 'z' 't' 'I' 'u' 'l' 'g' 'Y' 'k' '!' 's' 'G' 'C' 'h'\n",
      " 'E' 'd' 'f' 'S' 'm' 'Z' '^' 'v' '*' 'p' 'x' '@' 'O' 'M' '+' 'o' '#' 'w'\n",
      " 'e' 'N' 'K' 'c' 'L' 'A' 'n' 'y' 'X' 'D' 'a' 'W' '-' 'J' 'r']\n",
      "x.shape (20008, 19, 26)\n",
      "y.shape (20008, 19, 51)\n"
     ]
    }
   ],
   "source": [
    "with open('nettalk.data') as f:\n",
    "    data = f.readlines()[10:]\n",
    "X = []\n",
    "Y = []\n",
    "for line in data:\n",
    "    X.append(list(line.split()[0]))\n",
    "    Y.append(list(line.split()[1]))\n",
    "eng_alphabet = list({l for word in X for l in word})\n",
    "print(\"Letter alphabet\", eng_alphabet)\n",
    "ph_alphabet = np.array(list({l for word in Y for l in word})) #phoneme alphabet\n",
    "print(\"Phoneme alphabet\", ph_alphabet)\n",
    "# see\n",
    "# https://archive.ics.uci.edu/ml/machine-learning-databases/undocumented/connectionist-bench/nettalk/nettalk.names\n",
    "# for what phoneme symbols mean\n",
    "\n",
    "char_to_num = dict((c, i) for i, c in enumerate(eng_alphabet))\n",
    "num_to_char = dict((i, c) for i, c in enumerate(eng_alphabet))\n",
    "\n",
    "ph_to_num = dict((c, i) for i, c in enumerate(ph_alphabet))\n",
    "num_to_ph = dict((i, c) for i, c in enumerate(ph_alphabet))\n",
    "\n",
    "lengths = [len(word) for word in X]\n",
    "maxlen = max(lengths)\n",
    "\n",
    "#add zero padding at the end of each word\n",
    "x = np.zeros((len(X), maxlen, len(eng_alphabet)), dtype=np.bool)\n",
    "y = np.zeros((len(X), maxlen, len(ph_alphabet)), dtype=np.bool) \n",
    "y[:,:,ph_to_num['-']] = 1 #absense of letter sounds like silence\n",
    "for i, word in enumerate(X):\n",
    "    for t, char in enumerate(word):\n",
    "        x[i, t, char_to_num[char]] = 1\n",
    "        y[i, t, ph_to_num['-']] = 0\n",
    "        y[i, t, ph_to_num[Y[i][t]]] = 1\n",
    "    \n",
    "print(\"x.shape\", x.shape)\n",
    "print(\"y.shape\", y.shape)\n",
    "assert (np.sum(y, axis = 2) == 1).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19410 Train sequences\n",
      "397 Validation sequences\n",
      "201 Test sequences\n",
      "X_train shape:  (19410, 19, 26)\n",
      "Y_train shape:  (19410, 19, 51)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(x, y, random_state=0, test_size=0.01)\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, random_state=0, test_size=0.02)\n",
    "print(len(X_train), \"Train sequences\")\n",
    "print(len(X_val), \"Validation sequences\")\n",
    "print(len(X_test), \"Test sequences\")\n",
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(\"Y_train shape: \", Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/misha/.local/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/misha/.local/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/misha/.local/lib/python3.7/site-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/misha/.local/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/misha/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py:3994: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 19410 samples, validate on 397 samples\n",
      "Epoch 1/60\n",
      "19410/19410 [==============================] - 16s 843us/sample - loss: 0.7985 - acc: 0.4680 - val_loss: 0.3357 - val_acc: 0.7371\n",
      "Epoch 2/60\n",
      "19410/19410 [==============================] - 15s 770us/sample - loss: 0.2407 - acc: 0.8057 - val_loss: 0.2029 - val_acc: 0.8344\n",
      "Epoch 3/60\n",
      "19410/19410 [==============================] - 15s 785us/sample - loss: 0.1703 - acc: 0.8584 - val_loss: 0.1652 - val_acc: 0.8599\n",
      "Epoch 4/60\n",
      "19410/19410 [==============================] - 16s 812us/sample - loss: 0.1438 - acc: 0.8777 - val_loss: 0.1456 - val_acc: 0.8745\n",
      "Epoch 5/60\n",
      "19410/19410 [==============================] - 16s 839us/sample - loss: 0.1284 - acc: 0.8905 - val_loss: 0.1329 - val_acc: 0.8820\n",
      "Epoch 6/60\n",
      "19410/19410 [==============================] - 16s 846us/sample - loss: 0.1178 - acc: 0.8990 - val_loss: 0.1250 - val_acc: 0.8915\n",
      "Epoch 7/60\n",
      "19410/19410 [==============================] - 17s 851us/sample - loss: 0.1093 - acc: 0.9067 - val_loss: 0.1168 - val_acc: 0.8976\n",
      "Epoch 8/60\n",
      "19410/19410 [==============================] - 17s 851us/sample - loss: 0.1027 - acc: 0.9122 - val_loss: 0.1105 - val_acc: 0.9024\n",
      "Epoch 9/60\n",
      "19410/19410 [==============================] - 17s 852us/sample - loss: 0.0973 - acc: 0.9171 - val_loss: 0.1078 - val_acc: 0.9058\n",
      "Epoch 10/60\n",
      "19410/19410 [==============================] - 17s 874us/sample - loss: 0.0932 - acc: 0.9206 - val_loss: 0.1031 - val_acc: 0.9099\n",
      "Epoch 11/60\n",
      "19410/19410 [==============================] - 16s 812us/sample - loss: 0.0891 - acc: 0.9242 - val_loss: 0.1006 - val_acc: 0.9129\n",
      "Epoch 12/60\n",
      "19410/19410 [==============================] - 17s 850us/sample - loss: 0.0856 - acc: 0.9270 - val_loss: 0.0990 - val_acc: 0.9156\n",
      "Epoch 13/60\n",
      "19410/19410 [==============================] - 16s 833us/sample - loss: 0.0824 - acc: 0.9301 - val_loss: 0.0966 - val_acc: 0.9201\n",
      "Epoch 14/60\n",
      "19410/19410 [==============================] - 16s 841us/sample - loss: 0.0796 - acc: 0.9330 - val_loss: 0.0952 - val_acc: 0.9241\n",
      "Epoch 15/60\n",
      "19410/19410 [==============================] - 16s 844us/sample - loss: 0.0772 - acc: 0.9347 - val_loss: 0.0946 - val_acc: 0.9241\n",
      "Epoch 16/60\n",
      "19410/19410 [==============================] - 17s 873us/sample - loss: 0.0748 - acc: 0.9366 - val_loss: 0.0916 - val_acc: 0.9259\n",
      "Epoch 17/60\n",
      "19410/19410 [==============================] - 17s 879us/sample - loss: 0.0725 - acc: 0.9385 - val_loss: 0.0923 - val_acc: 0.9245\n",
      "Epoch 18/60\n",
      "19410/19410 [==============================] - 17s 881us/sample - loss: 0.0703 - acc: 0.9412 - val_loss: 0.0904 - val_acc: 0.9245\n",
      "Epoch 19/60\n",
      "19410/19410 [==============================] - 17s 884us/sample - loss: 0.0684 - acc: 0.9420 - val_loss: 0.0915 - val_acc: 0.9255\n",
      "Epoch 20/60\n",
      "19410/19410 [==============================] - 18s 935us/sample - loss: 0.0664 - acc: 0.9439 - val_loss: 0.0878 - val_acc: 0.9282\n",
      "Epoch 21/60\n",
      "19410/19410 [==============================] - 18s 906us/sample - loss: 0.0645 - acc: 0.9452 - val_loss: 0.0890 - val_acc: 0.9248\n",
      "Epoch 22/60\n",
      "19410/19410 [==============================] - 18s 908us/sample - loss: 0.0629 - acc: 0.9474 - val_loss: 0.0879 - val_acc: 0.9279\n",
      "Epoch 23/60\n",
      "19410/19410 [==============================] - 18s 914us/sample - loss: 0.0612 - acc: 0.9487 - val_loss: 0.0866 - val_acc: 0.9286\n",
      "Epoch 24/60\n",
      "19410/19410 [==============================] - 17s 889us/sample - loss: 0.0596 - acc: 0.9499 - val_loss: 0.0876 - val_acc: 0.9276\n",
      "Epoch 25/60\n",
      "19410/19410 [==============================] - 18s 918us/sample - loss: 0.0583 - acc: 0.9513 - val_loss: 0.0878 - val_acc: 0.9282\n",
      "Epoch 26/60\n",
      "19410/19410 [==============================] - 18s 920us/sample - loss: 0.0567 - acc: 0.9527 - val_loss: 0.0868 - val_acc: 0.9279\n",
      "Epoch 27/60\n",
      "19410/19410 [==============================] - 18s 920us/sample - loss: 0.0554 - acc: 0.9535 - val_loss: 0.0870 - val_acc: 0.9272\n",
      "Epoch 28/60\n",
      "19410/19410 [==============================] - 18s 920us/sample - loss: 0.0541 - acc: 0.9550 - val_loss: 0.0864 - val_acc: 0.9262\n",
      "Epoch 29/60\n",
      "19410/19410 [==============================] - 18s 918us/sample - loss: 0.0527 - acc: 0.9561 - val_loss: 0.0859 - val_acc: 0.9303\n",
      "Epoch 30/60\n",
      "19410/19410 [==============================] - 18s 919us/sample - loss: 0.0515 - acc: 0.9573 - val_loss: 0.0891 - val_acc: 0.9259\n",
      "Epoch 31/60\n",
      "19410/19410 [==============================] - 18s 922us/sample - loss: 0.0502 - acc: 0.9581 - val_loss: 0.0844 - val_acc: 0.9337\n",
      "Epoch 32/60\n",
      "19410/19410 [==============================] - 18s 918us/sample - loss: 0.0490 - acc: 0.9597 - val_loss: 0.0862 - val_acc: 0.9299\n",
      "Epoch 33/60\n",
      "19410/19410 [==============================] - 18s 921us/sample - loss: 0.0480 - acc: 0.9598 - val_loss: 0.0855 - val_acc: 0.9316\n",
      "Epoch 34/60\n",
      "19410/19410 [==============================] - 18s 924us/sample - loss: 0.0468 - acc: 0.9613 - val_loss: 0.0859 - val_acc: 0.9316\n",
      "Epoch 35/60\n",
      "19410/19410 [==============================] - 18s 921us/sample - loss: 0.0458 - acc: 0.9621 - val_loss: 0.0852 - val_acc: 0.9296\n",
      "Epoch 36/60\n",
      "19410/19410 [==============================] - 18s 920us/sample - loss: 0.0446 - acc: 0.9631 - val_loss: 0.0866 - val_acc: 0.9303\n",
      "Epoch 37/60\n",
      "19410/19410 [==============================] - 19s 959us/sample - loss: 0.0437 - acc: 0.9639 - val_loss: 0.0891 - val_acc: 0.9299\n",
      "Epoch 38/60\n",
      "19410/19410 [==============================] - 19s 973us/sample - loss: 0.0426 - acc: 0.9652 - val_loss: 0.0878 - val_acc: 0.9306\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f3caa718610>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Masking(mask_value=0, input_shape=(maxlen, len(eng_alphabet))))\n",
    "model.add(Bidirectional(LSTM(32, return_sequences=True), input_shape=(maxlen, len(eng_alphabet))))\n",
    "model.add(Bidirectional(LSTM(32, return_sequences=True)))\n",
    "model.add(TimeDistributed(Dense(51, activation='softmax')))\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=60, batch_size=32, validation_data=(X_val, Y_val),\n",
    "          callbacks = [keras.callbacks.EarlyStopping(patience=7)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201/201 [==============================] - 0s 104us/sample - loss: 0.0842 - acc: 0.9339\n",
      "test loss, test acc: [0.08416331552006119, 0.93391776]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, Y_test, batch_size=128)\n",
    "print(\"test loss, test acc:\", results)\n",
    "model.save('translit.h5')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "maxlen = 19\n",
    "def predict(word, model):\n",
    "    x = np.zeros((1, maxlen, len(eng_alphabet)), dtype = np.bool)\n",
    "    for t, char in enumerate(word):\n",
    "        x[0, t, char_to_num[char]] = 1\n",
    "    y = np.argmax(model.predict(x), axis = 2)[0][:len(word)]\n",
    "    return([num_to_ph[num] for num in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transcribe phonemes into russian\n",
    "ph_to_rus = {   \n",
    "  \"a\":\"о\",\n",
    "  \"b\":\"б\",\n",
    "  \"c\":\"o\",\n",
    "  \"d\":\"д\",\n",
    "  \"e\":\"эй\", # ей\n",
    "  \"f\":\"ф\",\n",
    "  \"g\":\"г\",\n",
    "  \"h\":\"х\",\n",
    "  \"i\":\"и\",\n",
    "  \"k\":\"к\",\n",
    "  \"l\":\"л\",\n",
    "  \"m\":\"м\",\n",
    "  \"n\":\"н\",\n",
    "  \"o\":\"оу\",\n",
    "  \"p\":\"п\",\n",
    "  \"r\":\"р\",\n",
    "  \"s\":\"с\",\n",
    "  \"t\":\"т\",\n",
    "  \"u\":\"у\",\n",
    "  \"v\":\"в\",\n",
    "  \"w\":\"в\",\n",
    "  \"x\":\"э\",\n",
    "  \"y\":\"й\",\n",
    "  \"z\":\"з\",\n",
    "  \"A\":\"ай\",\n",
    "  \"C\":\"ч\",\n",
    "  \"D\":\"з\",\n",
    "  \"E\":\"э\",\n",
    "  \"G\":\"нг\", \n",
    "  \"I\":\"и\",\n",
    "  \"J\":\"дж\",\n",
    "  \"K\":\"кш\",\n",
    "  \"L\":\"л\", # или \"эл\"\n",
    "  \"M\":\"м\",\n",
    "  \"N\":\"н\",\n",
    "  \"O\":\"ой\",\n",
    "  \"Q\":\"кв\",\n",
    "  \"R\":\"ёр\",\n",
    "  \"S\":\"ш\",\n",
    "  \"T\":\"с\",\n",
    "  \"U\":\"у\",\n",
    "  \"W\":\"ау\",\n",
    "  \"X\":\"кс\",\n",
    "  \"Y\":\"ью\", #после гласной или в начале слова = ю, после согласной = ью\n",
    "  \"Z\":\"ж\",\n",
    "  \"@\":\"э\",\n",
    "  \"!\":\"ц\",\n",
    "  \"#\":\"гз\",\n",
    "  \"*\":\"в\",\n",
    "  \"^\":\"а\",\n",
    "  \"+\":\"уа\",\n",
    "  \"-\":\"\"\n",
    "}\n",
    "def translit(word, model):\n",
    "    phonemes = predict(word, model)\n",
    "    return ''.join([ph_to_rus[ph] for ph in phonemes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "тэлинг\n",
      "эджэкэйтэд\n",
      "калёрфал\n",
      "дисайсив\n",
      "руз\n",
      "хизинг\n",
      "дэзлинг\n",
      "айдлэтри\n",
      "дэвэлопмэнт\n",
      "рэпрэдакшэн\n",
      "рибэлйэс\n",
      "фёрвёр\n",
      "глифал\n",
      "доулфал\n",
      "хормфал\n",
      "битёрнэс\n",
      "диспайт\n",
      "ригёрдлэс\n",
      "копэрайт\n",
      "сикьюрэти\n"
     ]
    }
   ],
   "source": [
    "#some random english words not from the training set:\n",
    "wordlist = \"\"\"telling educated colorful decisive reuse hissing dazzling idolatry development reproduction\n",
    "rebellious fervor gleeful doleful harmful bitterness despite regardless copyright security\"\"\".split()\n",
    "for word in wordlist:\n",
    "    print(translit(word, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
